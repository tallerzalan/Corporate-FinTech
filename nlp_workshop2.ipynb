{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob: Sentiment Analysis &amp; Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Sentiment Analysis?\n",
    "\n",
    "Sentiment analysis is a method in NLP used to classify the emotion (or tone) and subjectiveness of human language. At the most common and basic level, the goal is to classify a text as positive, negative, or neutral in tone, and to determine how subjective it is. The aspect of subjectivity will only very briefly be noted in this workshop.\n",
    "\n",
    "At a more complex level, sentiment analysis is a technique used to classify the specific emotions in human language, such as angry, happy, sad, excited, etc. So instead of simply learning/classifying three classes (positive, negative, neutral), the goal is to involve many specific classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Use Sentiment Analysis?\n",
    "\n",
    "The actual usefulness of sentiment analysis depends on the industry using it, but the most common reason to use it involve scraping lots of data (e.g. twitter feeds or reddit comments) to determine how customers/users feel about a particular brand, product, or service. \n",
    "\n",
    "There is also a use for sentiment analysis when analyzing financial securities (stock market): if a large proportion of people shift in sentiment about a particular market or stock, that is going to affect the price of securities involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Uses\n",
    "\n",
    "* Insight into opinions on specific political policies\n",
    "* Brand monitoring (how is a brand perceived?)\n",
    "* Identify good and bad aspects of product or ads\n",
    "* Impact of changes in sentiment on securities markets\n",
    "* Will likely be used one day with virtual assistants and other AI\n",
    "* Hotels can use it to know how they can improve their property and service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import what we need\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF, Series\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "cols = ['airline_sentiment','airline_sentiment_confidence',\n",
    "        'airline','name','text']\n",
    "data = pd.read_csv('data/tweets.csv', usecols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the first 5 rows of our data. We will only be using the first two features, and the last feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  airline_sentiment  airline_sentiment_confidence         airline        name  \\\n0           neutral                        1.0000  Virgin America     cairdin   \n1          positive                        0.3486  Virgin America    jnardino   \n2           neutral                        0.6837  Virgin America  yvonnalynn   \n3          negative                        1.0000  Virgin America    jnardino   \n4          negative                        1.0000  Virgin America    jnardino   \n\n                                                text  \n0                @VirginAmerica What @dhepburn said.  \n1  @VirginAmerica plus you've added commercials t...  \n2  @VirginAmerica I didn't today... Must mean I n...  \n3  @VirginAmerica it's really aggressive to blast...  \n4  @VirginAmerica and it's a really big bad thing...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>airline_sentiment</th>\n      <th>airline_sentiment_confidence</th>\n      <th>airline</th>\n      <th>name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>cairdin</td>\n      <td>@VirginAmerica What @dhepburn said.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>positive</td>\n      <td>0.3486</td>\n      <td>Virgin America</td>\n      <td>jnardino</td>\n      <td>@VirginAmerica plus you've added commercials t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neutral</td>\n      <td>0.6837</td>\n      <td>Virgin America</td>\n      <td>yvonnalynn</td>\n      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>jnardino</td>\n      <td>@VirginAmerica it's really aggressive to blast...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>jnardino</td>\n      <td>@VirginAmerica and it's a really big bad thing...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity & Subjectivity Using TextBlob `sentiment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Basic Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using the TextBlob `sentiment` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TextBlob has a `sentiment` method that can be used on any `TextBlob` object. It returns two values:\n",
    "* polarity: value in range [-1, 1], indicating how negative or positive the text is (close to 0.0 is neutral).\n",
    "* subjectivity: value in range [0, 1], indicating how subjective the text is (1 is very subjective)\n",
    "\n",
    "This method is very basic, and there is a lot to be desired, but it can still be helpful if you don't have opportunity to train a classifier, and just need some rough results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is on the table \n",
      "(p=0.0, s=0.0) \n",
      "\n",
      "The food is green \n",
      "(p=-0.2, s=0.3) \n",
      "\n",
      "I don't like the food \n",
      "(p=0.0, s=0.0) \n",
      "\n",
      "I do not like the food \n",
      "(p=0.0, s=0.0) \n",
      "\n",
      "I like the food \n",
      "(p=0.0, s=0.0) \n",
      "\n",
      "I don't love the food \n",
      "(p=0.5, s=0.6) \n",
      "\n",
      "I do not love the food \n",
      "(p=-0.25, s=0.6) \n",
      "\n",
      "I hate the food \n",
      "(p=-0.8, s=0.9) \n",
      "\n",
      "I love the food \n",
      "(p=0.5, s=0.6) \n",
      "\n",
      "The food is delicious \n",
      "(p=1.0, s=1.0) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = [\"The food is on the table\", \"The food is green\", \"I don't like the food\",\n",
    "         \"I do not like the food\", \"I like the food\", \"I don't love the food\", \"I do not love the food\",\n",
    "         \"I hate the food\", \"I love the food\", \"The food is delicious\"]\n",
    "\n",
    "# analyze the sentences\n",
    "sentiments = [b.sentiment for b in [TextBlob(l) for l in lines]]\n",
    "for l,s in zip(lines, sentiments):\n",
    "    print('{} \\n(p={}, s={})'.format(l, s[0], s[1]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As seen above, this method doesn't recognize negative contractions (e.g. don't), and it has trouble with ambiguous works that can take on multiple meanings (e.g. like, which is also used for comparision)\n",
    "\n",
    "Let's see how it does with a couple book reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using The `sentiment` Method on Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get a subset of our data that contains only the first 10 rows that have a confidence level greater that 0.6. This is because we are uninterested in entries with a high level of uncertainty, because keeping low-confidence observations would reduce the certainty of evaluations that we will make later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get subset of tweets where confidence is > 0.6\n",
    "subset = data[data.airline_sentiment_confidence > 0.6]\\\n",
    "    .head(10).copy().reset_index(drop=True)\n",
    "tweets = subset.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  airline_sentiment  airline_sentiment_confidence         airline  \\\n0           neutral                        1.0000  Virgin America   \n1           neutral                        0.6837  Virgin America   \n2          negative                        1.0000  Virgin America   \n3          negative                        1.0000  Virgin America   \n4          negative                        1.0000  Virgin America   \n5          positive                        0.6745  Virgin America   \n6           neutral                        0.6340  Virgin America   \n7          positive                        0.6559  Virgin America   \n8          positive                        1.0000  Virgin America   \n9           neutral                        0.6769  Virgin America   \n\n              name                                               text  \n0          cairdin                @VirginAmerica What @dhepburn said.  \n1       yvonnalynn  @VirginAmerica I didn't today... Must mean I n...  \n2         jnardino  @VirginAmerica it's really aggressive to blast...  \n3         jnardino  @VirginAmerica and it's a really big bad thing...  \n4         jnardino  @VirginAmerica seriously would pay $30 a fligh...  \n5       cjmcginnis  @VirginAmerica yes, nearly every time I fly VX...  \n6            pilot  @VirginAmerica Really missed a prime opportuni...  \n7         dhepburn    @virginamerica Well, I didn't…but NOW I DO! :-D  \n8       YupitsTate  @VirginAmerica it was amazing, and arrived an ...  \n9  idk_but_youtube  @VirginAmerica did you know that suicide is th...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>airline_sentiment</th>\n      <th>airline_sentiment_confidence</th>\n      <th>airline</th>\n      <th>name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>cairdin</td>\n      <td>@VirginAmerica What @dhepburn said.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neutral</td>\n      <td>0.6837</td>\n      <td>Virgin America</td>\n      <td>yvonnalynn</td>\n      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>jnardino</td>\n      <td>@VirginAmerica it's really aggressive to blast...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>jnardino</td>\n      <td>@VirginAmerica and it's a really big bad thing...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>negative</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>jnardino</td>\n      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>positive</td>\n      <td>0.6745</td>\n      <td>Virgin America</td>\n      <td>cjmcginnis</td>\n      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>neutral</td>\n      <td>0.6340</td>\n      <td>Virgin America</td>\n      <td>pilot</td>\n      <td>@VirginAmerica Really missed a prime opportuni...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>positive</td>\n      <td>0.6559</td>\n      <td>Virgin America</td>\n      <td>dhepburn</td>\n      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>positive</td>\n      <td>1.0000</td>\n      <td>Virgin America</td>\n      <td>YupitsTate</td>\n      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>neutral</td>\n      <td>0.6769</td>\n      <td>Virgin America</td>\n      <td>idk_but_youtube</td>\n      <td>@VirginAmerica did you know that suicide is th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the `sentiment` predictions with each line in `subset`\n",
    "\n",
    "We want to get a sense of how each tweet is being classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica What @dhepburn said. \n",
      " 0.0 (target: neutral) \n",
      "\n",
      "@VirginAmerica I didn't today... Must mean I need to take another trip! \n",
      " -0.390625 (target: neutral) \n",
      "\n",
      "@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse \n",
      " 0.0062500000000000056 (target: negative) \n",
      "\n",
      "@VirginAmerica and it's a really big bad thing about it \n",
      " -0.3499999999999999 (target: negative) \n",
      "\n",
      "@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA \n",
      " -0.2083333333333333 (target: negative) \n",
      "\n",
      "@VirginAmerica yes, nearly every time I fly VX this “ear worm” won’t go away :) \n",
      " 0.4666666666666666 (target: positive) \n",
      "\n",
      "@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP \n",
      " 0.2 (target: neutral) \n",
      "\n",
      "@virginamerica Well, I didn't…but NOW I DO! :-D \n",
      " 1.0 (target: positive) \n",
      "\n",
      "@VirginAmerica it was amazing, and arrived an hour early. You're too good to me. \n",
      " 0.4666666666666666 (target: positive) \n",
      "\n",
      "@VirginAmerica did you know that suicide is the second leading cause of death among teens 10-24 \n",
      " 0.0 (target: neutral) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the tweets and predicted polarity line-by-line\n",
    "for i,t in enumerate(tweets):\n",
    "    s = TextBlob(t).sentiment\n",
    "    target = subset.airline_sentiment[i]\n",
    "    print(t, '\\n', '{} (target: {}) \\n'.format(s[0], target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This basic sentiment analyzer missed the mark on 3/10 tweets (2 neutral and 1 negative). That's not too bad, but these results are nothing to celebrate. The perfmance declines quite a bit with larger texts.\n",
    "\n",
    "Looking at the two tweets the `sentiment` method estimated incorrectly:\n",
    "\n",
    "**@VirginAmerica I didn't today... Must mean I need to take another trip!**\n",
    "This one is interpreted by the computer as negative, and perhaps it's correct. This one is full of ambiguity without any context, and that is probably why the target value in the set is neutral.\n",
    "\n",
    "**@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse**\n",
    "This one is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze polarity of each word in the last sentence above to see what's happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VirginAmerica 0.0 \n",
      "\n",
      "it 0.0 \n",
      "\n",
      "'s 0.0 \n",
      "\n",
      "really 0.2 \n",
      "\n",
      "aggressive 0.0 \n",
      "\n",
      "to 0.0 \n",
      "\n",
      "blast 0.0 \n",
      "\n",
      "obnoxious 0.0 \n",
      "\n",
      "entertainment 0.0 \n",
      "\n",
      "in 0.0 \n",
      "\n",
      "your 0.0 \n",
      "\n",
      "guests 0.0 \n",
      "\n",
      "faces 0.0 \n",
      "\n",
      "amp 0.0 \n",
      "\n",
      "they 0.0 \n",
      "\n",
      "have 0.0 \n",
      "\n",
      "little -0.1875 \n",
      "\n",
      "recourse 0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = TextBlob(tweets[2]).words\n",
    "for w in words: print(w, TextBlob(w).sentiment[0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can see that the `sentiment` method does not consider the words \"obnoxious\" or \"aggressive\" to be negative, which is a glaring problem for our analysis. This method is clearly limited and we need a better method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Naive Bayes Classifier for Sentiment Anlaysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use a Naive Bayes Classifier (included with TextBlob) to create a better sentiment analyzer. We will only train on a small portion of our data since it takes a while to train. However, even with a small amount of training data we can get better results than the `sentiment` method.\n",
    "\n",
    "There are other classifiers included with TextBlob, but this one is easy to use and gives good performance.\n",
    "\n",
    "We will start with three goals\n",
    "* learn to train and test/evaluate this classifier using a subset of our data\n",
    "* compare the performance to the original sentiment method\n",
    "* look at the features the classifier is extracting from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test sets\n",
    "\n",
    "* train the model on the first set\n",
    "* test/evaluate it on the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set below named `reduced` is reduced in dimensionality (keeping only the features/columns we care about).\n",
    "\n",
    "The `train` and `test` sets are created using something called a list comprehension. If you don't know what that is, it's okay, and you can look it up later. What is important is to know that the Naive Bayes classifier takes data in the form of a list of doubles, where each double is one observation (text, label), where label is the class label that belongs to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), ['airline_sentiment', 'text'])",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/nlp-workshop/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-workshop/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-workshop/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:142\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '(slice(None, None, None), ['airline_sentiment', 'text'])' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# get reduced set\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m reduced \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mairline_sentiment\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m      3\u001B[0m reduced\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mairline_sentiment\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m}, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# now create train and test sets for first 500 tweets\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# for the TextBlob classifier we need a list of doubles (string, target)\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-workshop/venv/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-workshop/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3628\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3623\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m         \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m         \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m         \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m-> 3628\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3629\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m   3631\u001B[0m \u001B[38;5;66;03m# GH#42269\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-workshop/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5637\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   5633\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   5634\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[1;32m   5635\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[1;32m   5636\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[0;32m-> 5637\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: (slice(None, None, None), ['airline_sentiment', 'text'])"
     ]
    }
   ],
   "source": [
    "# get reduced set\n",
    "reduced = data[:, ['airline_sentiment','text']].copy()\n",
    "reduced.rename(columns={'airline_sentiment': 'target'}, inplace=1)\n",
    "\n",
    "# now create train and test sets for first 500 tweets\n",
    "# for the TextBlob classifier we need a list of doubles (string, target)\n",
    "train = [(s, t) for s,t in zip(reduced.iloc[:350].text, reduced.iloc[:350].target)]\n",
    "test = [(s, t) for s,t in zip(reduced.iloc[350:500].text, reduced.iloc[350:500].target)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtextblob\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclassifiers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NaiveBayesClassifier\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# train\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m cl \u001B[38;5;241m=\u001B[39m NaiveBayesClassifier(\u001B[43mtrain\u001B[49m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# evaluate\u001B[39;00m\n\u001B[1;32m      7\u001B[0m cl\u001B[38;5;241m.\u001B[39maccuracy(test)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# import the classifier\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "# train\n",
    "cl = NaiveBayesClassifier(train)\n",
    "# evaluate\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a quick look at the distribution of class labels\n",
    "reduced.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The classes in the test set are pretty much balanced, but the classes in the entire reduced set are not balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's compare the 61% classifier accuracy to the performance of the `sentiment` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When accuracy isn't good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Need better scoring method for multi-class predictions**\n",
    "\n",
    "Regular accuracy is simply the ratio of number of correct predictions to total number of predictions made. This pays no attention to how many classes there are, or how well each one is predicted.\n",
    "\n",
    "**When it’s not good enough**\n",
    "* there are more than two classes (in our case there are 3)\n",
    "* there is an imbalance (at least one class with far fewer instances than another)\n",
    "\n",
    "If there is a strong imbalance (and this does happen) where there are two classes one only happens 5% of the time, if all we do is predict everything to be the majority class, then we will automatically get 95% accuracy. That's meaningless in such a case.\n",
    "\n",
    "**Precision and Recall are two useful metrics in these cases**\n",
    "\n",
    "Precision = TP / (TP + FP) : how often predictions of a specific class are correct\n",
    "\n",
    "TP : True Positive<br>\n",
    "FP : False Positive\n",
    "\n",
    "Recall = TP / (TP + FN) : how often specific classes are identified (not missed)\n",
    "\n",
    "FN : False Negative\n",
    "\n",
    "**Precision & Recall**\n",
    "\n",
    "Precision = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "Recall = $\\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a score function that will give precision and recall values for each class\n",
    "def score(true, predicted):\n",
    "    eq = np.equal\n",
    "    \n",
    "    t = np.array(true)\n",
    "    p = np.array(predicted)\n",
    "    \n",
    "    tp = np.array([eq((t == c)*(p == c), 1).sum() for c in np.unique(t)])\n",
    "    fp = np.array([eq((t != c)*(p == c), 1).sum() for c in np.unique(t)])\n",
    "    fn = np.array([eq((t == c)*(p != c), 1).sum() for c in np.unique(t)])\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    \n",
    "    return (np.unique(t), precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate classifier on larger set\n",
    "\\* **skip this; takes too long** \\*\n",
    "\n",
    "**With train/test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create new train and test sets\n",
    "# for the TextBlob classifier we need a list of doubles (string, target)\n",
    "\n",
    "# train = [(s, t) for s,t in zip(reduced.iloc[:1500].text, reduced.iloc[:1500].target)]\n",
    "# test = [(s, t) for s,t in zip(reduced.iloc[1500:2000].text, reduced.iloc[1500:2000].target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "# cl = NaiveBayesClassifier(train)\n",
    "\n",
    "# evaluate\n",
    "# cl.accuracy(test)\n",
    "# 0.786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Problems\n",
    "\n",
    "1. Create a pandas series of polarity values predicted for all entries in the reduced set using the sentiment method\n",
    "2. Create a column in the reduced set with class labels mapped from the polarity values in (1.) using the following rules:\n",
    "    - polarity  <   - 0.1 : ‘negative’\n",
    "    - polarity  >  0.1 : ‘positive’\n",
    "    - else : ‘neutral’\n",
    "3. Compute the accuracy of the predicted labels from (2.) for the same range as the test set [350:500]\n",
    "4. Update the score function to print a clean table of scores with (hint: use pandas)\n",
    "    - rows for precision and recall\n",
    "    - columns for class labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier: Digging Deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "`NaiveBayesClassifier` has a `classify` method that takes text (a single string) as an argument. This means that we can either classify some string that we choose to type by hand, or classify tweets from our test set individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify('I love this airline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = cl.prob_classify('I love this airline')\n",
    "probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8788493380472053"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.prob('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01575421132591375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.prob('negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can be useful if you want to make modifications to how something is classified by setting a threshold. For example, you may want to only classify something as positive if the probability exceeds 0.9, instead of it simply having the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Informative Features\n",
    "\n",
    "The method below gives us some insight into how the classifier is making decisions. For example, we can see that if a string contains the word \"great\", the there is are 8.7:1 odds that the string is positive instead of negative. All of the features are taken into account for one string, so that doesn't mean just because \"great\" is in the string it will be classified as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(no) = True           negati : neutra =      9.7 : 1.0\n",
      "         contains(great) = True           positi : negati =      9.7 : 1.0\n",
      "        contains(Thanks) = True           positi : negati =      8.7 : 1.0\n",
      "          contains(love) = True           positi : negati =      8.7 : 1.0\n",
      "        contains(thanks) = True           positi : negati =      6.9 : 1.0\n",
      "          contains(site) = True           negati : positi =      6.5 : 1.0\n",
      "           contains(not) = True           negati : positi =      6.0 : 1.0\n",
      "       contains(amazing) = True           positi : negati =      6.0 : 1.0\n",
      "         contains(Thank) = True           positi : negati =      6.0 : 1.0\n",
      "       contains(website) = True           negati : neutra =      5.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**How to interpret this:**\n",
    "* We are given rows that have `contains(feature) = True/False` and a comparison of two class labels with a ratio that indicates how likely one is over the other \n",
    "* The printed results are in descending order of importance\n",
    "* Ex: `contains(no) = True` gives the ratio of 9.7 : 1.0, showing that it is extremely likely to be negative rather than neutral\n",
    "* The default features for the Naive Bayes classifier are individual words found in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Features\n",
    "\n",
    "We are provided a method that serves one purpose: take a string and return a dictionary of all features in our classifier (individual words by default), and whether or not that word is in the string. It is essentially a binary feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(while)': False,\n",
       " 'contains(schedule)': False,\n",
       " 'contains(week)': False,\n",
       " 'contains(hard)': False,\n",
       " 'contains(sorry)': False,\n",
       " 'contains(t.co/zSuZTNAIJq)': False,\n",
       " 'contains(views)': False,\n",
       " 'contains(add)': False,\n",
       " 'contains(issue)': False,\n",
       " 'contains(quick)': False,\n",
       " 'contains(Andrews)': False,\n",
       " 'contains(Follow)': False,\n",
       " 'contains(enter)': False,\n",
       " 'contains(Many)': False,\n",
       " 'contains(t.co/UT5GrRwAaA)': False,\n",
       " 'contains(Holla)': False,\n",
       " 'contains(Same)': False,\n",
       " 'contains(cake)': False,\n",
       " 'contains(t.co/gLXFwP6nQH)': False,\n",
       " 'contains(NewsVP)': False,\n",
       " 'contains(24hrs)': False,\n",
       " 'contains(reimburse)': False,\n",
       " 'contains(makes)': False,\n",
       " 'contains(back-end)': False,\n",
       " 'contains(PrincessHalf)': False,\n",
       " 'contains(pros)': False,\n",
       " 'contains(if)': False,\n",
       " 'contains(wish)': False,\n",
       " 'contains(t.co/XZ6qeG3nef)': False,\n",
       " 'contains(bked)': False,\n",
       " 'contains(account)': False,\n",
       " 'contains(Lister)': False,\n",
       " 'contains(keeps)': False,\n",
       " 'contains(brand)': False,\n",
       " 'contains(jump)': False,\n",
       " 'contains(deals)': False,\n",
       " 'contains(Handily)': False,\n",
       " 'contains(has)': False,\n",
       " 'contains(charging)': False,\n",
       " 'contains(Debbie)': False,\n",
       " 'contains(ressie)': False,\n",
       " 'contains(time)': False,\n",
       " 'contains(t.co/UKdjjijroW)': False,\n",
       " 'contains(downtown)': False,\n",
       " 'contains(t.co/yPo7nYpRZl)': False,\n",
       " 'contains(2015)': False,\n",
       " 'contains(interesting)': False,\n",
       " 'contains(gon)': False,\n",
       " 'contains(answer)': False,\n",
       " 'contains(DFW)': False,\n",
       " 'contains(GMA)': False,\n",
       " 'contains(redirected)': False,\n",
       " 'contains(first)': False,\n",
       " 'contains(net)': False,\n",
       " 'contains(You’ve)': False,\n",
       " 'contains(100)': False,\n",
       " 'contains(last)': False,\n",
       " 'contains(sec)': False,\n",
       " 'contains(rain)': False,\n",
       " 'contains(b/c)': False,\n",
       " 'contains(having)': False,\n",
       " 'contains(SEA)': False,\n",
       " 'contains(Like)': False,\n",
       " 'contains(VirginAmerica)': False,\n",
       " 'contains(💗🇬🇧💗🇺🇸💗)': False,\n",
       " 'contains(taxes)': False,\n",
       " 'contains(Such)': False,\n",
       " 'contains(disappointing)': False,\n",
       " 'contains(t.co/SLLYIBE2vQ)': False,\n",
       " 'contains(come)': False,\n",
       " 'contains(wanted)': False,\n",
       " 'contains(might)': False,\n",
       " 'contains(back)': False,\n",
       " 'contains(JFK)': False,\n",
       " 'contains(bin)': False,\n",
       " 'contains(check-in)': False,\n",
       " 'contains(wan)': False,\n",
       " 'contains(AvalonHollywood)': False,\n",
       " 'contains(KETR)': False,\n",
       " 'contains(blast)': False,\n",
       " 'contains(spotify)': False,\n",
       " 'contains(financial)': False,\n",
       " 'contains(rockstars)': False,\n",
       " 'contains(2/27)': False,\n",
       " 'contains(Flightly)': False,\n",
       " 'contains(received)': False,\n",
       " 'contains(application)': False,\n",
       " 'contains(If)': False,\n",
       " 'contains(call/email)': False,\n",
       " 'contains(BOS-FLL)': False,\n",
       " 'contains(from)': False,\n",
       " 'contains(hours)': False,\n",
       " 'contains(59)': False,\n",
       " 'contains(delighted)': False,\n",
       " 'contains(Upgrade)': False,\n",
       " 'contains(Not)': False,\n",
       " 'contains(yet)': False,\n",
       " 'contains(Baggage)': False,\n",
       " 'contains(r)': False,\n",
       " 'contains(Applied)': False,\n",
       " 'contains(50)': False,\n",
       " 'contains(complimentary)': False,\n",
       " 'contains(be)': False,\n",
       " 'contains(because)': False,\n",
       " 'contains(Checkin)': False,\n",
       " 'contains(only)': False,\n",
       " 'contains(indicates)': False,\n",
       " 'contains(landing)': False,\n",
       " 'contains(refunding)': False,\n",
       " 'contains(fares)': False,\n",
       " 'contains(Really)': False,\n",
       " 'contains(Reuters)': False,\n",
       " 'contains(Row)': False,\n",
       " 'contains(Every)': False,\n",
       " 'contains(eye)': False,\n",
       " 'contains(midnight)': False,\n",
       " 'contains(congrats)': False,\n",
       " 'contains(Oscars)': False,\n",
       " 'contains(What)': False,\n",
       " 'contains(user)': False,\n",
       " 'contains(manage)': False,\n",
       " 'contains(disruption)': False,\n",
       " 'contains(BTW)': False,\n",
       " 'contains(hiring)': False,\n",
       " 'contains(Middle)': False,\n",
       " 'contains(putting)': False,\n",
       " 'contains(paying)': False,\n",
       " 'contains(rescheduled)': False,\n",
       " 'contains(RNP)': False,\n",
       " 'contains(change)': False,\n",
       " 'contains(hold)': False,\n",
       " 'contains(was)': False,\n",
       " 'contains(soft)': False,\n",
       " 'contains(please)': False,\n",
       " 'contains(ATWOnline)': False,\n",
       " 'contains(t.co/hy0VrfhjHt)': False,\n",
       " 'contains(non)': False,\n",
       " 'contains(longer)': False,\n",
       " 'contains(2-8)': False,\n",
       " 'contains(leading)': False,\n",
       " 'contains(faces)': False,\n",
       " 'contains(continues)': False,\n",
       " 'contains(response)': False,\n",
       " 'contains(You)': False,\n",
       " 'contains(emails)': False,\n",
       " 'contains(exhausted)': False,\n",
       " 'contains(Cancelled)': False,\n",
       " 'contains(our)': False,\n",
       " 'contains(TOMORROW)': False,\n",
       " 'contains(second)': False,\n",
       " 'contains(stylesheets)': False,\n",
       " 'contains(Q4)': False,\n",
       " 'contains(DO)': False,\n",
       " 'contains(register)': False,\n",
       " 'contains(Bandie)': False,\n",
       " 'contains(Use)': False,\n",
       " 'contains(When)': False,\n",
       " 'contains(NO)': False,\n",
       " 'contains(flyer)': False,\n",
       " 'contains(board)': False,\n",
       " \"contains('ve)\": False,\n",
       " 'contains(neverflyvirginforbusiness)': False,\n",
       " 'contains(SilverStatus)': False,\n",
       " 'contains(broken)': False,\n",
       " 'contains(butt)': False,\n",
       " 'contains(Very)': False,\n",
       " 'contains(posted)': False,\n",
       " 'contains(minutes)': False,\n",
       " 'contains(FiDiFamilies)': False,\n",
       " 'contains(missed)': False,\n",
       " 'contains(DC)': False,\n",
       " 'contains(permanently)': False,\n",
       " 'contains(March)': False,\n",
       " 'contains(sooner)': False,\n",
       " 'contains(looking)': False,\n",
       " 'contains(match)': False,\n",
       " 'contains(completely)': False,\n",
       " 'contains(Hands)': False,\n",
       " 'contains(Hey)': False,\n",
       " 'contains(assistance)': False,\n",
       " 'contains(airplanemodewason)': False,\n",
       " 'contains(get)': False,\n",
       " 'contains(sorted)': False,\n",
       " 'contains(blew)': False,\n",
       " 'contains(somehow)': False,\n",
       " 'contains(Boo)': False,\n",
       " 'contains(cabin)': False,\n",
       " 'contains(you)': False,\n",
       " 'contains(doctor)': False,\n",
       " 'contains(4:50)': False,\n",
       " 'contains(rescheduling)': False,\n",
       " 'contains(SFO-FLL)': False,\n",
       " 'contains(told)': False,\n",
       " 'contains(VAbeatsJblue)': False,\n",
       " 'contains(half)': False,\n",
       " 'contains(ugh)': False,\n",
       " 'contains(does)': False,\n",
       " 'contains(dog)': False,\n",
       " 'contains(picture)': False,\n",
       " 'contains(few)': False,\n",
       " 'contains(distribution)': False,\n",
       " 'contains(passenger)': False,\n",
       " 'contains(advise)': False,\n",
       " 'contains(begrudgingly)': False,\n",
       " 'contains(roasted)': False,\n",
       " 'contains(avail)': False,\n",
       " 'contains(soon)': False,\n",
       " 'contains(U)': False,\n",
       " 'contains(ever)': False,\n",
       " 'contains(virginmedia)': False,\n",
       " 'contains(NYC-JFK)': False,\n",
       " 'contains(behind)': False,\n",
       " 'contains(way)': False,\n",
       " 'contains(JKF)': False,\n",
       " 'contains(EWR)': False,\n",
       " 'contains(comfort)': False,\n",
       " 'contains(2A)': False,\n",
       " 'contains(recourse)': False,\n",
       " 'contains(offer)': False,\n",
       " 'contains(plz)': False,\n",
       " 'contains(FLL)': False,\n",
       " 'contains(View)': False,\n",
       " 'contains(can’t)': False,\n",
       " 'contains(why)': False,\n",
       " 'contains(mountains)': False,\n",
       " 'contains(globe)': False,\n",
       " 'contains(rockstar)': False,\n",
       " 'contains(possible)': False,\n",
       " 'contains(LadyGaga)': False,\n",
       " 'contains(dirty)': False,\n",
       " 'contains(fabulous)': False,\n",
       " 'contains(entertainment)': False,\n",
       " 'contains(purchased)': False,\n",
       " 'contains(landed)': False,\n",
       " 'contains(YOU)': False,\n",
       " 'contains(Dulles_Airport)': False,\n",
       " 'contains(April)': False,\n",
       " 'contains(as)': False,\n",
       " 'contains(IAD)': False,\n",
       " 'contains(mind)': False,\n",
       " 'contains(being)': False,\n",
       " 'contains(SuuperG)': False,\n",
       " 'contains(gt)': False,\n",
       " 'contains(Flighted)': False,\n",
       " 'contains(RT)': False,\n",
       " 'contains(status)': False,\n",
       " 'contains(FCmostinnovative)': False,\n",
       " 'contains(current)': False,\n",
       " 'contains(vendor)': False,\n",
       " 'contains(happening)': False,\n",
       " 'contains(hated)': False,\n",
       " 'contains(shrinerack)': False,\n",
       " 'contains(iced)': False,\n",
       " 'contains(Takes)': False,\n",
       " 'contains(guiltypleasures)': False,\n",
       " 'contains(anything)': False,\n",
       " 'contains(May)': False,\n",
       " 'contains(giving)': False,\n",
       " 'contains(refreshed)': False,\n",
       " 'contains(subsequent)': False,\n",
       " 'contains(weather)': False,\n",
       " 'contains(built)': False,\n",
       " 'contains(checking)': False,\n",
       " 'contains(heard)': False,\n",
       " 'contains(carrieunderwood)': False,\n",
       " 'contains(Call)': False,\n",
       " 'contains(facing)': False,\n",
       " 'contains(1st)': False,\n",
       " 'contains(front-end)': False,\n",
       " 'contains(even)': False,\n",
       " 'contains(button)': False,\n",
       " 'contains(peeps)': False,\n",
       " 'contains(Get)': False,\n",
       " 'contains(new)': False,\n",
       " 'contains(mobile)': False,\n",
       " 'contains(thank)': False,\n",
       " 'contains(moodlight)': False,\n",
       " 'contains(mentioned)': False,\n",
       " 'contains(turbulence)': False,\n",
       " 'contains(cause)': False,\n",
       " 'contains(eat)': False,\n",
       " 'contains(We)': False,\n",
       " 'contains(Gold)': False,\n",
       " 'contains(reset)': False,\n",
       " 'contains(Doom)': False,\n",
       " 'contains(precipitation)': False,\n",
       " 'contains(getting)': False,\n",
       " 'contains(want)': False,\n",
       " 'contains(least)': False,\n",
       " 'contains(90s)': False,\n",
       " 'contains(Why)': False,\n",
       " 'contains(cool)': False,\n",
       " 'contains(t.co/PYalebgkJt)': False,\n",
       " 'contains(recent)': False,\n",
       " 'contains(past)': False,\n",
       " 'contains(t.co/APtZpuROp4)': False,\n",
       " 'contains(apologies)': False,\n",
       " 'contains(89)': False,\n",
       " 'contains(SFO/LAX)': False,\n",
       " 'contains(says)': False,\n",
       " 'contains(t.co/2npXB6oBMr)': False,\n",
       " 'contains(concerned)': False,\n",
       " 'contains(dropped)': False,\n",
       " 'contains(earlier)': False,\n",
       " 'contains(wondering)': False,\n",
       " 'contains(Wifey)': False,\n",
       " 'contains(expectations)': False,\n",
       " 'contains(That)': False,\n",
       " 'contains(sanity)': False,\n",
       " 'contains(Got)': False,\n",
       " 'contains(Funny)': False,\n",
       " 'contains(see.Very)': False,\n",
       " 'contains(dhepburn)': False,\n",
       " 'contains(910)': False,\n",
       " 'contains(Gon)': False,\n",
       " 'contains(follow)': False,\n",
       " 'contains(white)': False,\n",
       " 'contains(Having)': False,\n",
       " 'contains(chat)': False,\n",
       " 'contains(t.co/RHKaMx9VF5)': False,\n",
       " 'contains(trust)': False,\n",
       " 'contains(hour)': False,\n",
       " 'contains(Valley)': False,\n",
       " 'contains(imagine)': False,\n",
       " 'contains(points)': False,\n",
       " 'contains(luv)': False,\n",
       " 'contains(gentleman)': False,\n",
       " 'contains(rep)': False,\n",
       " 'contains(After)': False,\n",
       " 'contains(👏)': False,\n",
       " 'contains(city’)': False,\n",
       " 'contains(andchexmix)': False,\n",
       " 'contains(more)': False,\n",
       " 'contains(Angeles)': False,\n",
       " 'contains(winds)': False,\n",
       " 'contains(PLEASE)': False,\n",
       " 'contains(month)': False,\n",
       " 'contains(bill)': False,\n",
       " 'contains(needs)': False,\n",
       " 'contains(supposed)': False,\n",
       " 'contains(kicked)': False,\n",
       " 'contains(revue)': False,\n",
       " 'contains(red)': False,\n",
       " 'contains(882)': False,\n",
       " 'contains(pairings)': False,\n",
       " 'contains(883)': False,\n",
       " 'contains(surgery)': False,\n",
       " 'contains(girls)': False,\n",
       " 'contains(CarrieUnderwood)': False,\n",
       " 'contains(momma)': False,\n",
       " 'contains(this)': True,\n",
       " 'contains(Worst)': False,\n",
       " 'contains(guests)': False,\n",
       " 'contains(when)': False,\n",
       " 'contains(SSal)': False,\n",
       " 'contains(X)': False,\n",
       " 'contains(hope)': False,\n",
       " 'contains(YOUR)': False,\n",
       " 'contains(ChrysiChrysic)': False,\n",
       " 'contains(Include)': False,\n",
       " 'contains(Still)': False,\n",
       " 'contains(represents)': False,\n",
       " 'contains(Oscars2015)': False,\n",
       " 'contains(MeetTheFleet)': False,\n",
       " 'contains(reply)': False,\n",
       " 'contains(desk)': False,\n",
       " 'contains(spend)': False,\n",
       " 'contains(Thank)': False,\n",
       " 'contains(due)': False,\n",
       " 'contains(And)': False,\n",
       " 'contains(p)': False,\n",
       " 'contains(problem)': False,\n",
       " 'contains(paperwork)': False,\n",
       " 'contains(section)': False,\n",
       " 'contains(shows)': False,\n",
       " 'contains(😂)': False,\n",
       " 'contains(pilots)': False,\n",
       " 'contains(VirginAtlantic)': False,\n",
       " 'contains(Elevate)': False,\n",
       " 'contains(minimal)': False,\n",
       " 'contains(doing)': False,\n",
       " 'contains(severely)': False,\n",
       " 'contains(day)': False,\n",
       " 'contains(Was)': False,\n",
       " 'contains(disappointed)': False,\n",
       " 'contains(degrees)': False,\n",
       " 'contains(gave)': False,\n",
       " 'contains(MayweatherPacquiao)': False,\n",
       " 'contains(JetBlue)': False,\n",
       " 'contains(bubbly)': False,\n",
       " 'contains(Arms)': False,\n",
       " 'contains(watching)': False,\n",
       " 'contains(VX358)': False,\n",
       " 'contains(really)': False,\n",
       " 'contains(anytime)': False,\n",
       " 'contains(2/24)': False,\n",
       " 'contains(SFOtoBOS)': False,\n",
       " 'contains(TODAY)': False,\n",
       " 'contains(in🇺🇸2y)': False,\n",
       " 'contains(team)': False,\n",
       " 'contains(gusty)': False,\n",
       " 'contains(amazing)': False,\n",
       " 'contains(line)': False,\n",
       " 'contains(Deals)': False,\n",
       " 'contains(10)': False,\n",
       " 'contains(song)': False,\n",
       " 'contains(unexpected)': False,\n",
       " 'contains(lame)': False,\n",
       " 'contains(food)': False,\n",
       " 'contains(me)': True,\n",
       " 'contains(done)': False,\n",
       " 'contains(Race)': False,\n",
       " 'contains(along)': False,\n",
       " 'contains(pre-check)': False,\n",
       " 'contains(Airline)': False,\n",
       " 'contains(BestCrew)': False,\n",
       " 'contains(weRin)': False,\n",
       " 'contains(appointments)': False,\n",
       " 'contains(emailed)': False,\n",
       " 'contains(stranded)': False,\n",
       " 'contains(said)': False,\n",
       " 'contains(😃)': False,\n",
       " 'contains(uncomfortable)': False,\n",
       " 'contains(DM)': False,\n",
       " 'contains(Lady)': False,\n",
       " 'contains(Another)': False,\n",
       " 'contains(round)': False,\n",
       " 'contains(lost)': False,\n",
       " 'contains(mention)': False,\n",
       " 'contains(Monday)': False,\n",
       " 'contains(t.co/vC6Keulg2J)': False,\n",
       " 'contains(early)': False,\n",
       " 'contains(neverflyvirgin)': False,\n",
       " 'contains(forward)': False,\n",
       " 'contains(price)': False,\n",
       " 'contains(Awesome)': False,\n",
       " 'contains(😢)': False,\n",
       " 'contains(Travelzoo)': False,\n",
       " 'contains(worm”)': False,\n",
       " 'contains(check)': False,\n",
       " 'contains(🍷👍💺✈️)': False,\n",
       " 'contains(Dallas-Austin)': False,\n",
       " 'contains(monday)': False,\n",
       " 'contains(Terrible)': False,\n",
       " 'contains(find)': False,\n",
       " 'contains(dislike)': False,\n",
       " 'contains(boy)': False,\n",
       " 'contains(BOS-LAS)': False,\n",
       " 'contains(shaker)': False,\n",
       " 'contains(updates)': False,\n",
       " 'contains(no)': True,\n",
       " 'contains(sneaky)': False,\n",
       " 'contains(one)': False,\n",
       " 'contains(OSCARS2105)': False,\n",
       " 'contains(virgin)': False,\n",
       " 'contains(yesterday)': False,\n",
       " 'contains(inquired)': False,\n",
       " 'contains(t.co/KEK5pDMGiF)': False,\n",
       " 'contains(t.co/wU3LbCNcr9)': False,\n",
       " 'contains(Palm)': False,\n",
       " 'contains(position)': False,\n",
       " 'contains(business)': False,\n",
       " 'contains(rise)': False,\n",
       " 'contains(better)': False,\n",
       " 'contains(direct)': False,\n",
       " 'contains(AmericanAir)': False,\n",
       " 'contains(t.co/PxdEL1nq3l)': False,\n",
       " 'contains(550)': False,\n",
       " 'contains(secure)': False,\n",
       " 'contains(asap)': False,\n",
       " 'contains(missing)': False,\n",
       " 'contains(t.co/DnStITRzWy)': False,\n",
       " 'contains(tickets)': False,\n",
       " 'contains(t.co/F2LFULCbQ7)': False,\n",
       " 'contains(2014)': False,\n",
       " 'contains(kitty)': False,\n",
       " 'contains(itinerary)': False,\n",
       " 'contains(innovation)': False,\n",
       " 'contains(styling)': False,\n",
       " 'contains(buy)': False,\n",
       " 'contains(noair)': False,\n",
       " 'contains(either)': False,\n",
       " \"contains('ll)\": False,\n",
       " 'contains(into)': False,\n",
       " 'contains(selecting)': False,\n",
       " 'contains(tomorrow)': False,\n",
       " 'contains(Shame)': False,\n",
       " 'contains(Bags)': False,\n",
       " 'contains(playing)': False,\n",
       " 'contains(769)': False,\n",
       " 'contains(policy)': False,\n",
       " 'contains(happy)': False,\n",
       " 'contains(BOS)': False,\n",
       " 'contains(pay)': False,\n",
       " 'contains(CheapFlights)': False,\n",
       " 'contains(shown)': False,\n",
       " 'contains(10:50AM)': False,\n",
       " 'contains(ladygaga)': False,\n",
       " 'contains(Comps)': False,\n",
       " 'contains(days)': False,\n",
       " 'contains(smh)': False,\n",
       " 'contains(Austin)': False,\n",
       " 'contains(First)': False,\n",
       " 'contains(biztravel)': False,\n",
       " 'contains(😥)': False,\n",
       " 'contains(attendant)': False,\n",
       " 'contains(husband)': False,\n",
       " 'contains(nonstop)': False,\n",
       " 'contains(process)': False,\n",
       " 'contains(name)': False,\n",
       " 'contains(I’m)': False,\n",
       " 'contains(2:10pm)': False,\n",
       " 'contains(jessicajaymes)': False,\n",
       " 'contains(confirmation)': False,\n",
       " 'contains(adding)': False,\n",
       " 'contains(city)': False,\n",
       " 'contains(Had)': False,\n",
       " 'contains(tech)': False,\n",
       " 'contains(good)': False,\n",
       " 'contains(seems)': False,\n",
       " 'contains(t.co/tvB5zbzVhg)': False,\n",
       " 'contains(taking)': True,\n",
       " 'contains(Cool)': False,\n",
       " 'contains(confirmed)': False,\n",
       " 'contains(mean)': False,\n",
       " 'contains(someone)': False,\n",
       " 'contains(spending)': False,\n",
       " 'contains(lax)': False,\n",
       " 'contains(Trying)': False,\n",
       " 'contains(entered)': False,\n",
       " 'contains(had)': False,\n",
       " 'contains(assets)': False,\n",
       " 'contains(t.co/rGYwJBbhm4)': False,\n",
       " 'contains(0769)': False,\n",
       " 'contains(remove)': False,\n",
       " 'contains(LAS)': False,\n",
       " 'contains(hipster)': False,\n",
       " 'contains(been)': False,\n",
       " 'contains(No)': False,\n",
       " 'contains(guy)': False,\n",
       " 'contains(7D)': False,\n",
       " 'contains(Budapest)': False,\n",
       " 'contains(applied)': False,\n",
       " 'contains(hotel)': False,\n",
       " 'contains(so)': False,\n",
       " 'contains(seriously)': False,\n",
       " 'contains(99)': False,\n",
       " 'contains(around)': False,\n",
       " 'contains(FreyaBevan_Fund)': False,\n",
       " 'contains(become)': False,\n",
       " 'contains(leaving)': False,\n",
       " 'contains(promised)': False,\n",
       " 'contains(Dulles)': False,\n",
       " 'contains(4Q)': False,\n",
       " 'contains(sounds)': False,\n",
       " 'contains(big)': False,\n",
       " 'contains(compatible)': False,\n",
       " 'contains(pretty)': False,\n",
       " 'contains(drink)': False,\n",
       " 'contains(destroyed)': False,\n",
       " 'contains(uphold)': False,\n",
       " 'contains(t.co/SSUVWwkyHH)': False,\n",
       " 'contains(suck)': False,\n",
       " 'contains(hrs)': False,\n",
       " 'contains(working)': False,\n",
       " 'contains(vegan)': False,\n",
       " 'contains(using)': False,\n",
       " 'contains(Keep)': False,\n",
       " \"contains('s)\": False,\n",
       " 'contains(incubator)': False,\n",
       " 'contains(access)': False,\n",
       " 'contains(heyyyy)': False,\n",
       " 'contains(able)': False,\n",
       " 'contains(side)': False,\n",
       " 'contains(two)': False,\n",
       " 'contains(i)': False,\n",
       " 'contains(Can)': False,\n",
       " 'contains(ur)': False,\n",
       " 'contains(dude)': False,\n",
       " 'contains(t.co/pX8hQOKS3R)': False,\n",
       " 'contains(birthday)': False,\n",
       " 'contains(Congrats)': False,\n",
       " 'contains(💜✈)': False,\n",
       " 'contains(Springs)': False,\n",
       " 'contains(iol)': False,\n",
       " 'contains(most)': False,\n",
       " 'contains(Sad)': False,\n",
       " 'contains(advantage)': False,\n",
       " 'contains(both)': False,\n",
       " 'contains(expected)': False,\n",
       " 'contains(6)': False,\n",
       " 'contains(things)': False,\n",
       " 'contains(flight🍸)': False,\n",
       " 'contains(Grand)': False,\n",
       " 'contains(biz)': False,\n",
       " 'contains(would)': False,\n",
       " 'contains(absolutely)': False,\n",
       " 'contains(t.co/H952rDKTqy”)': False,\n",
       " 'contains(evening)': False,\n",
       " 'contains(paid)': False,\n",
       " 'contains(914-329-0185)': False,\n",
       " 'contains(bound)': False,\n",
       " 'contains(Silicon)': False,\n",
       " 'contains(G)': False,\n",
       " 'contains(damaged)': False,\n",
       " 'contains(adore)': False,\n",
       " 'contains(fl1289)': False,\n",
       " 'contains(is)': True,\n",
       " 'contains(flying)': False,\n",
       " 'contains(customer)': False,\n",
       " 'contains(Handle)': False,\n",
       " 'contains(Waited)': False,\n",
       " 'contains(Booking)': False,\n",
       " 'contains(On)': False,\n",
       " 'contains(Gaga)': False,\n",
       " 'contains(apparently)': False,\n",
       " 'contains(seat)': False,\n",
       " 'contains(four)': False,\n",
       " 'contains(brought)': False,\n",
       " 'contains(scared)': False,\n",
       " 'contains(shame)': False,\n",
       " 'contains(elevate)': False,\n",
       " 'contains(sunset)': False,\n",
       " 'contains(t.co/1AGR9knCpf)': False,\n",
       " 'contains(Help😍)': False,\n",
       " 'contains(wow)': False,\n",
       " 'contains(excited)': False,\n",
       " 'contains(👸)': False,\n",
       " 'contains(bet)': False,\n",
       " 'contains(should)': False,\n",
       " 'contains(guys)': False,\n",
       " 'contains(normal)': False,\n",
       " 'contains(Whenever)': False,\n",
       " 'contains(member😒)': False,\n",
       " 'contains(❤️)': False,\n",
       " 'contains(AM)': False,\n",
       " 'contains(Problems)': False,\n",
       " 'contains(flight)': True,\n",
       " 'contains(use)': False,\n",
       " 'contains(iconography)': False,\n",
       " 'contains(horrible)': False,\n",
       " 'contains(which)': False,\n",
       " 'contains(wing)': False,\n",
       " 'contains(headed)': False,\n",
       " 'contains(TSA)': False,\n",
       " 'contains(88.9)': False,\n",
       " 'contains(Without)': False,\n",
       " 'contains(upgrade)': False,\n",
       " 'contains(down)': False,\n",
       " 'contains(couple)': False,\n",
       " 'contains(full)': False,\n",
       " 'contains(3)': False,\n",
       " 'contains(w)': False,\n",
       " 'contains(‘select)': False,\n",
       " 'contains(RenttheRunway)': False,\n",
       " 'contains(27)': False,\n",
       " 'contains(Prince)': False,\n",
       " 'contains(support)': False,\n",
       " 'contains(reallytallchris)': False,\n",
       " 'contains(NOW)': False,\n",
       " 'contains(messages)': False,\n",
       " 'contains(diehardvirgin)': False,\n",
       " 'contains(went)': False,\n",
       " 'contains(class)': False,\n",
       " 'contains(Status)': False,\n",
       " 'contains(soooo)': False,\n",
       " 'contains(what)': False,\n",
       " 'contains(💕💕)': False,\n",
       " 'contains(money)': False,\n",
       " 'contains(open)': False,\n",
       " 'contains(going)': False,\n",
       " 'contains(t.co/enIQg0buzj)': False,\n",
       " 'contains(work)': False,\n",
       " 'contains(thx)': False,\n",
       " 'contains(airlines)': False,\n",
       " 'contains(☺️👍)': False,\n",
       " 'contains(sorrynotsorry)': False,\n",
       " 'contains(tribute)': False,\n",
       " 'contains(Creates)': False,\n",
       " 'contains(mechanical)': False,\n",
       " 'contains(tacky)': False,\n",
       " 'contains(luggage)': False,\n",
       " 'contains(beyond)': False,\n",
       " 'contains(EVER)': False,\n",
       " 'contains(arrived)': False,\n",
       " 'contains(fare)': False,\n",
       " 'contains(Los)': False,\n",
       " 'contains(drivers)': False,\n",
       " 'contains(achieves)': False,\n",
       " 'contains(refund)': False,\n",
       " 'contains(free)': False,\n",
       " 'contains(silver)': False,\n",
       " 'contains(Will)': False,\n",
       " 'contains(Well)': False,\n",
       " 'contains(nearly)': False,\n",
       " 'contains(temperature)': False,\n",
       " 'contains(na)': False,\n",
       " 'contains(track)': False,\n",
       " 'contains(recline)': False,\n",
       " 'contains(yall)': False,\n",
       " 'contains(glad)': False,\n",
       " 'contains(code)': False,\n",
       " 'contains(wine)': False,\n",
       " 'contains(Good)': False,\n",
       " 'contains(feet)': False,\n",
       " 'contains(Dallas)': False,\n",
       " \"contains(didn't…but)\": False,\n",
       " 'contains(1230)': False,\n",
       " 'contains(job)': False,\n",
       " 'contains(standby)': False,\n",
       " 'contains(by)': False,\n",
       " 'contains(gate)': False,\n",
       " 'contains(Quick)': False,\n",
       " 'contains(easy)': False,\n",
       " 'contains(inflight)': False,\n",
       " 'contains(SJC)': False,\n",
       " 'contains(outstanding)': False,\n",
       " 'contains(afford)': False,\n",
       " 'contains(u)': False,\n",
       " 'contains(provided)': False,\n",
       " 'contains(start)': False,\n",
       " 'contains(the)': False,\n",
       " 'contains(help)': False,\n",
       " 'contains(Soon)': False,\n",
       " \"contains('re)\": False,\n",
       " 'contains(worstflightever)': False,\n",
       " 'contains(nicely)': False,\n",
       " 'contains(skies)': False,\n",
       " 'contains(touchdown)': False,\n",
       " 'contains(FastCompany)': False,\n",
       " 'contains(salt)': False,\n",
       " 'contains(Because)': False,\n",
       " 'contains(during)': False,\n",
       " 'contains(shared)': False,\n",
       " 'contains(desktop)': False,\n",
       " 'contains(safety)': False,\n",
       " 'contains(are)': False,\n",
       " 'contains(t.co/5B2agFd8c4)': False,\n",
       " 'contains(🙉)': False,\n",
       " 'contains(welcome)': False,\n",
       " 'contains(over)': False,\n",
       " 'contains(super)': False,\n",
       " 'contains(Site)': False,\n",
       " 'contains(Easily)': False,\n",
       " 'contains(reservation)': False,\n",
       " 'contains(Thx)': False,\n",
       " 'contains(❄️❄️❄️)': False,\n",
       " 'contains(HELP)': False,\n",
       " 'contains(banned)': False,\n",
       " 'contains(until)': False,\n",
       " 'contains(feel)': False,\n",
       " 'contains(of)': False,\n",
       " 'contains(Mostly)': False,\n",
       " 'contains(passengers)': False,\n",
       " 'contains(across)': False,\n",
       " 'contains(t.co/VPqEm31XUQ)': False,\n",
       " 'contains(😘)': False,\n",
       " 'contains(infant)': False,\n",
       " 'contains(Friday)': False,\n",
       " 'contains(prefer)': False,\n",
       " 'contains(t.co/oA2dRfAoQ2)': False,\n",
       " 'contains(t.co/UJfS9Zi6kd)': False,\n",
       " 'contains(united)': False,\n",
       " 'contains(dfw-lax)': False,\n",
       " 'contains(Hi)': False,\n",
       " 'contains(lt)': False,\n",
       " 'contains(Love/gratitude.mpower)': False,\n",
       " 'contains(email)': False,\n",
       " 'contains(30)': False,\n",
       " 'contains(2nd)': False,\n",
       " 'contains(airport)': False,\n",
       " 'contains(Sentinel)': False,\n",
       " 'contains(upgrades)': False,\n",
       " 'contains(receive)': False,\n",
       " 'contains(cross-browser)': False,\n",
       " 'contains(met)': False,\n",
       " 'contains(😍👌)': False,\n",
       " 'contains(ball)': False,\n",
       " 'contains(F)': False,\n",
       " 'contains(thing)': False,\n",
       " 'contains(expensive)': False,\n",
       " 'contains(In)': False,\n",
       " 'contains(screen)': False,\n",
       " 'contains(DREAM)': False,\n",
       " 'contains(24)': False,\n",
       " 'contains(Greetingz)': False,\n",
       " 'contains(order)': False,\n",
       " 'contains(delay)': False,\n",
       " 'contains(large)': False,\n",
       " 'contains(Time)': False,\n",
       " 'contains(min)': False,\n",
       " 'contains(9am)': False,\n",
       " 'contains(did)': False,\n",
       " 'contains(an)': False,\n",
       " 'contains(student)': False,\n",
       " 'contains(nomorevirgin)': False,\n",
       " 'contains(they)': False,\n",
       " 'contains(Seats)': False,\n",
       " 'contains(classics)': False,\n",
       " 'contains(ordered)': False,\n",
       " 'contains(always)': False,\n",
       " 'contains(wonked)': False,\n",
       " 'contains(t.co/tZZJhuIbCH)': False,\n",
       " 'contains(JPERHI)': False,\n",
       " 'contains(tonite)': False,\n",
       " 'contains(browsers)': False,\n",
       " 'contains(area)': False,\n",
       " 'contains(LOVE)': False,\n",
       " 'contains(Business)': False,\n",
       " 'contains(market)': False,\n",
       " 'contains(interested)': False,\n",
       " 'contains(tossed)': False,\n",
       " 'contains(york)': False,\n",
       " 'contains(people)': False,\n",
       " 'contains(see)': False,\n",
       " 'contains(report)': False,\n",
       " 'contains(customerservice)': False,\n",
       " 'contains(show)': False,\n",
       " 'contains(crew)': False,\n",
       " 'contains(America)': False,\n",
       " 'contains(yes)': False,\n",
       " 'contains(Love)': False,\n",
       " 'contains(VA370)': False,\n",
       " 'contains(dancing)': False,\n",
       " 'contains(end)': False,\n",
       " 'contains(338)': False,\n",
       " 'contains(800)': False,\n",
       " 'contains(713)': False,\n",
       " 'contains(t.co/CnctL7G1ef)': False,\n",
       " 'contains(or)': False,\n",
       " 'contains(Martin)': False,\n",
       " 'contains(flights)': False,\n",
       " 'contains(Points)': False,\n",
       " 'contains(match.Got)': False,\n",
       " 'contains(links)': False,\n",
       " 'contains(friends)': False,\n",
       " 'contains(booked)': False,\n",
       " 'contains(seatbelt)': False,\n",
       " 'contains(SFO/EWR)': False,\n",
       " 'contains(DCA)': False,\n",
       " 'contains(route)': False,\n",
       " 'contains(😁)': False,\n",
       " 'contains(page)': False,\n",
       " 'contains(greyed)': False,\n",
       " 'contains(commercials)': False,\n",
       " 'contains(premium)': False,\n",
       " 'contains(beautiful)': False,\n",
       " 'contains(bucks)': False,\n",
       " 'contains(cold)': False,\n",
       " 'contains(site)': False,\n",
       " 'contains(PDX)': False,\n",
       " 'contains(their)': False,\n",
       " 'contains(right)': False,\n",
       " 'contains(positive)': False,\n",
       " 'contains(Have)': False,\n",
       " 'contains(freddieawards)': False,\n",
       " 'contains(where)': True,\n",
       " 'contains(self-service)': False,\n",
       " 'contains(video)': False,\n",
       " 'contains(winning)': False,\n",
       " 'contains(choppy)': False,\n",
       " 'contains(amp)': False,\n",
       " 'contains(t.co/EwwGi97gdx)': False,\n",
       " 'contains(phone)': False,\n",
       " 'contains(weeks)': False,\n",
       " 'contains(claim)': False,\n",
       " 'contains(three)': False,\n",
       " 'contains(much)': False,\n",
       " 'contains(anyone)': False,\n",
       " 'contains(have)': True,\n",
       " 'contains(Ca)': False,\n",
       " 'contains(before)': False,\n",
       " 'contains(Hats)': False,\n",
       " 'contains(Baldwin)': False,\n",
       " 'contains(One)': False,\n",
       " 'contains(benefits)': False,\n",
       " 'contains(oscars2015)': False,\n",
       " 'contains(kids)': False,\n",
       " \"contains('d)\": False,\n",
       " 'contains(how)': False,\n",
       " 'contains(w/2)': False,\n",
       " 'contains(ROCK)': False,\n",
       " 'contains(every)': False,\n",
       " 'contains(experience)': False,\n",
       " 'contains(cross)': False,\n",
       " 'contains(very)': False,\n",
       " 'contains(prime)': False,\n",
       " 'contains(win)': False,\n",
       " 'contains(Who)': False,\n",
       " 'contains(t.co/GsB2J3c4gM)': False,\n",
       " 'contains(making)': False,\n",
       " 'contains(away)': False,\n",
       " 'contains(snow)': False,\n",
       " 'contains(🌞✈)': False,\n",
       " 'contains(Investor)': False,\n",
       " 'contains(any)': False,\n",
       " 'contains(center)': False,\n",
       " 'contains(worse)': False,\n",
       " 'contains(OscarsCountdown)': False,\n",
       " 'contains(413)': False,\n",
       " 'contains(but)': False,\n",
       " 'contains(out)': False,\n",
       " 'contains(Sign)': False,\n",
       " 'contains(connecting)': False,\n",
       " 'contains(assist)': False,\n",
       " 'contains(think)': False,\n",
       " 'contains(designated)': False,\n",
       " 'contains(VX)': False,\n",
       " 'contains(💗)': False,\n",
       " 'contains(w/the)': False,\n",
       " 'contains(know)': False,\n",
       " 'contains(understand)': False,\n",
       " 'contains(lot)': False,\n",
       " 'contains(selected👎)': False,\n",
       " 'contains(7AM)': False,\n",
       " 'contains(delays)': False,\n",
       " 'contains(like)': False,\n",
       " 'contains(t.co/vhp2GtDWPk)': False,\n",
       " 'contains(Must)': False,\n",
       " 'contains(less)': False,\n",
       " 'contains(barely)': False,\n",
       " 'contains(9)': False,\n",
       " 'contains(t.co/aqZWecOkk2)': False,\n",
       " 'contains(hand)': False,\n",
       " 'contains(intern)': False,\n",
       " 'contains(together)': False,\n",
       " 'contains(will)': False,\n",
       " 'contains(Flight)': False,\n",
       " 'contains(spruce)': False,\n",
       " 'contains(website)': False,\n",
       " 'contains(iPad)': False,\n",
       " 'contains(Lots)': False,\n",
       " 'contains(great)': False,\n",
       " 'contains(on.Easy)': False,\n",
       " 'contains(backtowinter)': False,\n",
       " 'contains(say)': False,\n",
       " 'contains(Is)': False,\n",
       " 'contains(charged)': False,\n",
       " 'contains(Lofty)': False,\n",
       " 'contains(story)': False,\n",
       " 'contains(gone)': False,\n",
       " 'contains(program)': False,\n",
       " 'contains(fail)': False,\n",
       " 'contains(Arab)': False,\n",
       " 'contains(tracking)': False,\n",
       " 'contains(give)': False,\n",
       " 'contains(714)': False,\n",
       " 'contains(calling)': False,\n",
       " 'contains(pleasecomeback)': False,\n",
       " 'contains(films)': False,\n",
       " 'contains(t.co/Dw5nf0ibtr)': False,\n",
       " 'contains(SouthwestAir)': False,\n",
       " 'contains(todays)': False,\n",
       " 'contains(after)': False,\n",
       " 'contains(long)': False,\n",
       " 'contains(Are)': False,\n",
       " 'contains(urgent)': False,\n",
       " 'contains(moose)': False,\n",
       " 'contains(go)': False,\n",
       " 'contains(trying)': False,\n",
       " 'contains(shift)': False,\n",
       " 'contains(watch)': False,\n",
       " 'contains(at)': False,\n",
       " 'contains(among)': False,\n",
       " 'contains(iPhone)': False,\n",
       " 'contains(who)': False,\n",
       " 'contains(MCO)': False,\n",
       " 'contains(DTW)': False,\n",
       " 'contains(Nice)': False,\n",
       " 'contains(hi)': False,\n",
       " 'contains(failing)': False,\n",
       " 'contains(Men)': False,\n",
       " 'contains(TTINAC11)': False,\n",
       " 'contains(step)': False,\n",
       " 'contains(graphics)': False,\n",
       " 'contains(faster)': False,\n",
       " 'contains(inconvenience)': False,\n",
       " 'contains(helping)': False,\n",
       " 'contains(web)': False,\n",
       " 'contains(beats)': False,\n",
       " 'contains(hahaha)': False,\n",
       " 'contains(276)': False,\n",
       " 'contains(PHL)': False,\n",
       " 'contains(year)': False,\n",
       " 'contains(fav)': False,\n",
       " 'contains(demo)': False,\n",
       " 'contains(drinks)': False,\n",
       " 'contains(number)': False,\n",
       " 'contains(sendambien)': False,\n",
       " 'contains(LAX)': False,\n",
       " 'contains(info)': False,\n",
       " 'contains(Sat)': False,\n",
       " 'contains(morning)': False,\n",
       " 'contains(depart)': False,\n",
       " 'contains(looks)': False,\n",
       " 'contains(SoundOfMusic)': False,\n",
       " 'contains(Or)': False,\n",
       " 'contains(scanned)': False,\n",
       " 'contains(best)': False,\n",
       " 'contains(redcarpet)': False,\n",
       " ...}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.extract_features('I have no idea where this flight is taking me')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying From Within a TextBlob\n",
    "\n",
    "We can perform classification on the contents of a TextBlob object using an existing classifier (like the one we created earlier (named cl). The usefulness of this might seem questionable, since you can just pass a normal string to the classifier. However, something you will be doing other work with some text in the form of a blob, and then when you need to perform classification, you don't have to go back and get the raw string.\n",
    "\n",
    "Using a clssifier in a `TextBlob` is as easy as passing the classifier as an argument when you create the blob.\n",
    "\n",
    "**Note:** The classifier must be one that you have already trained.\n",
    "\n",
    "Let's look at a couple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob('I loved the flight', classifier=cl)\n",
    "b.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob('I hated the flight', classifier=cl)\n",
    "b.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our classifier probably didn't encounter the word \"hate\" or \"hated\". We can update our model to improve classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Existing Classifiers With New Data\n",
    "\n",
    "Our classifier obviously failed us when we tried to classify the string \"I hate this flight.\"\n",
    "We have the option of easily updating our classifier with new data, so let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new data is also a list of tuples\n",
    "# be sure the class labels are correct\n",
    "updates = [('I hated flying', 'negative'), ('I hate flying', 'negative'),\n",
    "           ('I hate this airline', 'negative'), ('I hated the seats', 'negative')]\n",
    "cl.update(updates)  # this is unfortunately slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ignore the output `True`\n",
    "\n",
    "**Note:** If you get the error `too many values to unpack (expected 2)`, try re-running the cell where we created the train/test sets and create/train the classifier from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have updated our classifier with new data, let's see how our original sentence is classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how it does now using 'I hated the flight'\n",
    "b = TextBlob('I hated the flight', classifier=cl) # update\n",
    "b.classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An now we have the correct classification of `'negative'`\n",
    "\n",
    "If you do not get the correct class, try running the update cell once more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Other Classifiers\n",
    "\n",
    "TextBlob has a number of built in classifiers, all of which can be found in the documentation at the link below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://textblob.readthedocs.io/en/dev/api_reference.html#api-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pratice Problems\n",
    "\n",
    "1. Train a decision tree classifier on the first 350 tweets in the reduced set (the training set from earlier) — call it something other than cl — and print/examine the tree structure using pseudocode method (hint: wrap in print)\n",
    "2. Compute the accuracy on the test set [350:500] and compare to the Naive Bayes accuracy\n",
    "3. Compare the precision and recall scores for the two classifiers. Does the decision tree perform better on any of the classes? (hint: remember that these classify one item at a time)\n",
    "4. Create a new “balanced” training set of 50 observations from each class and update the current Naive Bayes (cl)\n",
    "5. Score the updated classifier. Have the scores improved? How about accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}